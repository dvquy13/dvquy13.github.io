<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2020-02-17">
<meta name="keywords" content="cloud, google cloud platform">

<title>From Model to Production: Deploying Your Machine Learning Solution on Google Cloud ‚Äì DvQ</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../avatar.png" rel="icon" type="image/png">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NH6GYY9FZV"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-NH6GYY9FZV', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>
<!-- Inter -->
<link rel="preconnect" href="https://rsms.me/">
<link rel="stylesheet" href="https://rsms.me/inter/inter.css">
<!-- Roboto Mono -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100..700;1,100..700&amp;display=swap" rel="stylesheet">


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">DvQ</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Blog Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/dvquy/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/dvquy13"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/dvquys"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">From Model to Production: Deploying Your Machine Learning Solution on Google Cloud</h1>
            <p class="subtitle lead">Transforming a Laptop-Trained ML Model into a Scalable Batch Processing Pipeline using GCP‚Äôs Dataproc</p>
                                <div class="quarto-categories">
                <div class="quarto-category">tech</div>
                <div class="quarto-category">machine learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 17, 2020</p>
      </div>
    </div>
    
      
    </div>
    

  <div>
    <div class="keywords">
      <div class="block-title">Keywords</div>
      <p>cloud, google cloud platform</p>
    </div>
  </div>
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-targeted-audience" id="toc-the-targeted-audience" class="nav-link" data-scroll-target="#the-targeted-audience">The targeted&nbsp;audience</a></li>
  <li><a href="#agenda" id="toc-agenda" class="nav-link" data-scroll-target="#agenda">Agenda</a></li>
  <li><a href="#approaches" id="toc-approaches" class="nav-link" data-scroll-target="#approaches">Approaches</a>
  <ul class="collapse">
  <li><a href="#about-writing-codes" id="toc-about-writing-codes" class="nav-link" data-scroll-target="#about-writing-codes">About writing&nbsp;codes</a></li>
  <li><a href="#about-computing-resources" id="toc-about-computing-resources" class="nav-link" data-scroll-target="#about-computing-resources">About computing resources</a></li>
  </ul></li>
  <li><a href="#step-by-step-instructions" id="toc-step-by-step-instructions" class="nav-link" data-scroll-target="#step-by-step-instructions">Step-by-step instructions</a>
  <ul class="collapse">
  <li><a href="#create-a-gcp-project-and-enable-necessary-components" id="toc-create-a-gcp-project-and-enable-necessary-components" class="nav-link" data-scroll-target="#create-a-gcp-project-and-enable-necessary-components">Create a GCP project and enable necessary components</a></li>
  <li><a href="#environment-setup" id="toc-environment-setup" class="nav-link" data-scroll-target="#environment-setup">Environment setup</a></li>
  <li><a href="#clean-up" id="toc-clean-up" class="nav-link" data-scroll-target="#clean-up">Clean up</a></li>
  </ul></li>
  <li><a href="#explain-codebase" id="toc-explain-codebase" class="nav-link" data-scroll-target="#explain-codebase">Explain codebase</a></li>
  <li><a href="#further-discussion" id="toc-further-discussion" class="nav-link" data-scroll-target="#further-discussion">Further discussion</a>
  <ul class="collapse">
  <li><a href="#apache-spark-for-bigger-data" id="toc-apache-spark-for-bigger-data" class="nav-link" data-scroll-target="#apache-spark-for-bigger-data">Apache Spark for bigger&nbsp;data</a></li>
  <li><a href="#apache-airflow-for-orchestration" id="toc-apache-airflow-for-orchestration" class="nav-link" data-scroll-target="#apache-airflow-for-orchestration">Apache Airflow for orchestration</a></li>
  <li><a href="#local-development" id="toc-local-development" class="nav-link" data-scroll-target="#local-development">Local development</a></li>
  <li><a href="#unit-testing" id="toc-unit-testing" class="nav-link" data-scroll-target="#unit-testing">Unit testing</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  <li><a href="#credits" id="toc-credits" class="nav-link" data-scroll-target="#credits">Credits</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<div class="callout callout-style-simple callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
This article is originally published in <a href="https://medium.com/vinid/what-i-learned-about-deploying-machine-learning-application-c7bfd654f999">VinID Engineering</a>
</div>
</div>
<div class="callout-body-container callout-body">

</div>
</div>
<p>Imagine a company named Rainbow imports boxes of flowers and need to classify them into species. For six months, they have some staff label the boxes manually. Now, they hire you to build a Machine Learning model to do the task.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://cdn-images-1.medium.com/max/800/1*7bnLKsChXq94QjtAiRn40w.png" class="img-fluid figure-img"></p>
<figcaption>Source: <a href="https://hackernoon.com/top-5-machine-learning-projects-for-beginners-47b184e7837f">Hackernoon</a></figcaption>
</figure>
</div>
<p>With a small amount of labelled data as input and tons of experience working on Kaggle projects, you quickly develop a 95% accuracy using simple RandomForestClassifier from the popular scikit-learn library. Nice. Stakeholders approve and ask you when you could <strong>deploy that model to production.</strong></p>
<p>Hmm, deploy a model from my laptop?&nbsp;‚Ä¶</p>
<p>In case you wonder, I hope this tutorial will help you understand one among some common and most simple approaches. The diagram below depicts how we will use Google Cloud Platform to do the job in a batch-processing manner.</p>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/1200/1*xb0UAAcHwbus-dfXLu5SCw.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://cdn-images-1.medium.com/max/1200/1*xb0UAAcHwbus-dfXLu5SCw.png" class="img-fluid"></a></p>
</div>
<p>I choose the <a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris data set</a> as our input to help you see how our approach works with small-sized problems. All the codes are in <a href="https://github.com/dvquy13/gcp_ml_pipeline">this repo</a>.</p>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Like many other self-taught data people, I am familiar with manipulating data and develop a model on my laptop.</p>
<p>However, when you‚Äôre solving real-world problems, your duty does not stop after you deliver a presentation. You will have to think about how to bring that solution to the production environment.</p>
<p>Over the last few months, I have tried to deploy multiple computing pipelines. They are different in their scopes and complexity, ranging from processing a dozen of MB to 400 GB data per run. In this article, I want to summarize and share what I learned.</p>
</section>
<section id="the-targeted-audience" class="level2">
<h2 class="anchored" data-anchor-id="the-targeted-audience">The targeted&nbsp;audience</h2>
<p>This post is for data analysts/scientists who want to deploy their local solution, especially those without a software engineering background.</p>
<p>You will need Cloud Dataproc to proceed. This product allows you to spin up a cluster of machines to run your computing job in a distributed manner. Please refer to <a href="https://cloud.google.com/dataproc/">this documentation</a> if you don‚Äôt know what Dataproc is.</p>
</section>
<section id="agenda" class="level2">
<h2 class="anchored" data-anchor-id="agenda">Agenda</h2>
<ol type="1">
<li>Discuss the approach</li>
<li>Step-by-step instructions to create the infrastructure and run the pipeline</li>
<li>Explain codebase</li>
<li>Introduce other extended components, including Big Data processing with Apache Spark, scheduler with Airflow, local development environment, unit testing</li>
<li>Summary</li>
</ol>
</section>
<section id="approaches" class="level2">
<h2 class="anchored" data-anchor-id="approaches">Approaches</h2>
<section id="about-writing-codes" class="level3">
<h3 class="anchored" data-anchor-id="about-writing-codes">About writing&nbsp;codes</h3>
<p><strong>Instead of writing a long script to do everything, we break a pipeline into tasks and checkpoint interim data to disk.</strong> For example, after doing preprocess on train and test data, we dump both the data outputs and the transformer to Google Cloud Storage. We then load those objects as inputs for the next step.</p>
<p>This strategy has several purposes. First, for a long-running task, if a job fails at one of the last steps, we can re-run the pipeline from the nearest checkpoint rather than wasting time and resources restarting the whole pipeline. Second, it allows us to (1) debug more easily, (2) get alert when things break and (3) monitor interim outputs. Lastly, decoupled components can be understood more clearly, and easier to be replaced or extended later.</p>
</section>
<section id="about-computing-resources" class="level3">
<h3 class="anchored" data-anchor-id="about-computing-resources">About computing resources</h3>
<p>Normally for a small input size, we are fine with setting up a single virtual machine on the cloud. However, in some companies with mature cloud practice, the overhead of managing that VM is a type of cost that is difficult to justify. Especially when we have better options. <strong>For instance, Cloud Dataproc provides us with virtual machines that only live for the duration of one run, thereby free us from managing the machines.</strong> In this post, we explore Dataproc as our main engine for all the computing process.</p>
</section>
</section>
<section id="step-by-step-instructions" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="step-by-step-instructions">Step-by-step instructions</h2>
<section id="create-a-gcp-project-and-enable-necessary-components" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="create-a-gcp-project-and-enable-necessary-components">Create a GCP project and enable necessary components</h3>
<ol type="1">
<li>üëâ Create a free GCP account with $300 credit by going to <a href="https://console.cloud.google.com/getting-started">console.cloud.google.com</a>. <strong>Beware that by following this tutorial, you might incur a cost of about $0.2‚Äì$0.5.</strong></li>
</ol>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*gNpMH0Knm_ElpJSexisAag.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://cdn-images-1.medium.com/max/800/1*gNpMH0Knm_ElpJSexisAag.png" class="img-fluid"></a></p>
</div>
<ol start="2" type="1">
<li>üëâ Click Billing at the left sidebar and initiate a billing account to be able to use the components used in this tutorial</li>
</ol>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*HRbgGB_s3KwK8kxRiaTUPQ.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://cdn-images-1.medium.com/max/800/1*HRbgGB_s3KwK8kxRiaTUPQ.png" class="img-fluid"></a></p>
</div>
<ol start="3" type="1">
<li><p>üëâ Select <strong>Library</strong>, then search and enable the following API: Cloud Dataproc, Cloud Storage and Cloud Firestore.</p></li>
<li><p>üëâ Navigate to the Firestore either by scrolling the sidebar to the left or search from the top menu bar. When you arrive at the below screen, choose <strong>SELECT NATIVE MODE</strong>, then choose <code>us-east1</code> as the location.</p></li>
</ol>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*mBmW_jb_412UYimWp9QaoQ.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://cdn-images-1.medium.com/max/800/1*mBmW_jb_412UYimWp9QaoQ.png" class="img-fluid"></a></p>
</div>
</section>
<section id="environment-setup" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="environment-setup">Environment setup</h3>
<section id="step-1-launch-terminal-window" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="step-1-launch-terminal-window">Step 1: Launch terminal window</h4>
<ol start="5" type="1">
<li>üëâ At the home page of your GCP project, select the command button to the right of your menubar. The CloudShell window then appears as you can see below:</li>
</ol>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*6HVcsv6LqFEaf8eOIt6Xyg.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://cdn-images-1.medium.com/max/800/1*6HVcsv6LqFEaf8eOIt6Xyg.png" class="img-fluid"></a></p>
</div>
<ol type="1">
<li>üëâ Launch Cloud Shell Editor:</li>
</ol>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*T5WH0YKLnpH3gWq1Lj_BZA.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://cdn-images-1.medium.com/max/800/1*T5WH0YKLnpH3gWq1Lj_BZA.png" class="img-fluid"></a></p>
</div>
<p>It‚Äôs recommended to use Cloud Shell to follow this tutorial. However, if you‚Äôre using Linux and want to use terminal on your local machine, make sure you first <a href="https://cloud.google.com/sdk/install">install the Google Cloud SDK</a> and firebase CLI.</p>
</section>
<section id="step-2-clone-github-repo" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="step-2-clone-github-repo">Step 2: Clone Github repo</h4>
<ol start="7" type="1">
<li>üëâ In the Terminal window:</li>
</ol>
<pre class="shell"><code>git clonehttps://github.com/dvquy13/gcp_ml_pipeline.git
cd gcp_ml_pipeline</code></pre>
<ol start="8" type="1">
<li>üëâ Select <code>File</code> then open the file <code>gcp_ml_pipeline/configs/.project_env</code>:</li>
</ol>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*cqPTo5ebmac4e7aO-Alnug.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7"><img src="https://cdn-images-1.medium.com/max/800/1*cqPTo5ebmac4e7aO-Alnug.png" class="img-fluid"></a></p>
</div>
<ol start="9" type="1">
<li>üëâ Replace the values enclosed by &lt;&gt;. For the <code>GCP_PROJECT</code>, you need to provide the <code>id</code> of your GCP project. For the remaining, feel free to choose some random names for the global variables that identify your resources. The final output looks like this:</li>
</ol>
<pre class="shell"><code>GCP_PROJECT='zinc-primer-230105'
GCS_BUCKET=dvquys-tut-gcp-ml-pipeline
DATA_LOCATION=us-east1
BQ_DATASET=tut_iris
BQ_ORG_TABLE=F_ORIGINAL
CLUSTER_NAME=iris-pred</code></pre>
<ol start="10" type="1">
<li>üëâ Grant <code>execute</code> permission to the folder scripts by running the command: <code>chmod +x -R&nbsp;./scripts</code>. Then, run&nbsp;<code>./scripts/00_import_data_to_bigquery.sh</code>. <a href="https://github.com/dvquy13/gcp_ml_pipeline/blob/master/scripts/00_import_data_to_bigquery.sh">Link to the script</a>.</li>
</ol>
</section>
<section id="step-3-create-dataproc-cluster-and-submit-jobs" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="step-3-create-dataproc-cluster-and-submit-jobs">Step 3: Create Dataproc cluster and submit&nbsp;jobs</h4>
<p>We use Makefile to orchestrate our actions. You can find it here: https://github.com/dvquy13/gcp_ml_pipeline/blob/master/Makefile.</p>
<p>Ô∏èNow, run the following commands in sequence:</p>
<ol type="1">
<li><p><code>make create-dataproc-cluster</code>: <strong>This command creates a Dataproc cluster</strong>. The <code>single-node</code> flag indicates that this is a cluster containing only one machine. <code>n1-standard-1</code> is the cheapest machine we can rent. To install Python packages, we supply the <code>metadata</code> and <code>initialization-actions</code> params.</p></li>
<li><p><code>make build</code>: <strong>Package your code</strong>, including your source code and other 3rd party libraries that you can not pre-install when creating the cluster (PyYAML for example). To submit a job to the cluster, we will send these codes to those machines via the <code>gcloud dataproc jobs submit pyspark</code> command.</p></li>
<li><p><code>make submit-job ENV=dev MODULE=data_import TASK=query_train_pred</code>: <strong>Submit job cloning input data for training and predicting.</strong> The <code>submit-job</code> <code>make</code> command allows you to use this interface to run on both local and development environments.</p></li>
<li><p><code>make submit-job ENV=dev MODULE=feature_engineer TASK=normalize</code>: <strong>Prepare features.</strong> In this illustrative example, we choose to include only normalization in the pipeline. After learning the normalization parameters from the train data set, we save those configurations for later usage.</p></li>
<li><p><code>make submit-job ENV=dev MODULE=model TASK=fit</code>: <strong>Train model.</strong> Here we build a pipeline consisting of 2 steps, Normalization and Logistic Regression. After that, we persist the fit pipeline.</p></li>
<li><p><code>make submit-job ENV=dev MODULE=predict TASK=batch_predict</code>: <strong>Batch predict.</strong> This job demonstrates the process when you use your learned model to make predictions.</p></li>
<li><p><code>make submit-job ENV=dev MODULE=predict TASK=store_predictions</code>: <strong>Store predictions.</strong> The reason we do not combine this with the above step is two-fold. First, writing to a database often takes time and requires several retries. Second, we write to a document database like Cloud Firestore because when other team uses, they typically retrieve one document per query. However, there are times when we want to inspect the whole batch of predictions (e.g.&nbsp;debugging, count number of documents scored more than 0.9). For this query pattern, we will better off using the persisted outputs from the previous step, stored as parquet files in Cloud Storage.</p></li>
<li><p><code>make delete-dataproc-cluster</code>: <strong>Delete Dataproc cluster.</strong> After the process finishes, delete the cluster so no further cost incurs.</p></li>
</ol>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*meEStEyORtyi06DTLioGVg.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="https://cdn-images-1.medium.com/max/800/1*meEStEyORtyi06DTLioGVg.png" class="img-fluid"></a></p>
</div>
<p>Succeeded Dataproc&nbsp;jobs</p>
<p>You can see that your predictions are stored at Cloud Firestore by accessing its web console.</p>
<div class="column-page">
<p><a href="https://cdn-images-1.medium.com/max/800/1*XEcsap97Y0cCiYoPbgSa3g.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="https://cdn-images-1.medium.com/max/800/1*XEcsap97Y0cCiYoPbgSa3g.png" class="img-fluid"></a></p>
</div>
<p>Firestore populated with predictions</p>
<p>Along the way, you will see that the output data of each step is persisted in Cloud Storage. I use <code>parquet</code> rather than <code>CSV</code> as the serialization format because it can embed schema information (therefore you do not have to specify column types when reading) and reduce storage size. For more detail, please refer to <a href="https://towardsdatascience.com/the-best-format-to-save-pandas-data-414dca023e0d">this benchmark</a>.</p>
</section>
</section>
<section id="clean-up" class="level3">
<h3 class="anchored" data-anchor-id="clean-up">Clean up</h3>
<ol start="11" type="1">
<li>üëâ Finally, when you‚Äôre done exploring the results, you can delete all resources by running these commands:</li>
</ol>
<pre class="shell"><code>./scripts/01_erase_resources.sh
./scripts/02_disable_resources.sh
./scripts/03_delete_project.sh</code></pre>
</section>
</section>
<section id="explain-codebase" class="level2">
<h2 class="anchored" data-anchor-id="explain-codebase">Explain codebase</h2>
<p><code>scripts/</code>: This directory contains some initial scripts, which are the steps to help you set things up. In practice, I also favor using script rather than user interfaces such as web console because it is self-documented and easy for others to follow the exact steps.</p>
<p><code>configs/</code>: Store all the arguments that need to be set initially.&nbsp;<code>.project_env</code> is a file to store the global variables used to work with GCP. We also have the <code>runtime.yaml</code>, where we <a href="https://medium.com/@kinghuang/docker-compose-anchors-aliases-extensions-a1e4105d70bd">use Anchor, Alias and Extension in YAML</a> to define runtime parameters for multiple environments. Both of these files serve as a centralized config store so that we can easily look up and make changes, instead of finding the configs scattered elsewhere in the code.</p>
<p><code>Makefile</code>: Originally Makefile is used to orchestrate the build process in C programming language. But it has done so well out of being just a shortcut so people start using it to facilitate ML model development. I have seen many tutorials using this tool, including <a href="https://developerzen.com/best-practices-writing-production-grade-pyspark-jobs-cb688ac4d20f">the one that inspires me to design my Pyspark codebase</a>.In this small project, we also use Makefile to save us a lot of time. As you can see above in <strong>Step 3</strong>, I put there our frequently used commands so that I can easily type <code>make &lt;something&gt;</code> to run a particular step.</p>
<p><code>iris_pred/</code>: Source code.</p>
<p><code>main.py</code>: is the interface to all tasks. This file parses the arguments to load config and get the job name, then call <code>analyze</code> function in <code>entry_point.py</code> from the appropriate module.</p>
<p><code>jobs/</code>: contain tasks as modules. Inside <code>jobs</code>, we have one module corresponding to a step in our pipeline. All these modules expose an <code>entry_point.py</code> file where we unify the API to easily and consistently communicate with <code>main.py</code>.</p>
<details>
<summary>
Code: train.py
</summary>
<div class="code-with-filename">
<div class="code-with-filename-file">
<pre><strong>iris_pred/jobs/model/train.py</strong></pre>
</div>
<div class="sourceCode" id="cb4" data-filename="iris_pred/jobs/model/train.py"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>logger <span class="op">=</span> logging.getLogger(<span class="va">__name__</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> subprocess</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> shared.io_handler <span class="im">import</span> IOHandler</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> jobs.feature_engineer.normalize <span class="im">import</span> FeatureNormalizer</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.externals <span class="im">import</span> joblib</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Trainer:</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, params, load: <span class="bu">bool</span>):</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.params <span class="op">=</span> params</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.io_handler <span class="op">=</span> IOHandler(params)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.interim_output_path, <span class="va">self</span>.final_output_path <span class="op">=</span> <span class="op">\</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._get_fpath()</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.normalizer <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learner <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pipeline <span class="op">=</span> <span class="va">None</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _get_fpath(<span class="va">self</span>):</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        interim_output_path <span class="op">=</span> <span class="op">\</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'../</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>params<span class="sc">.</span>io<span class="sc">.</span>pipeline<span class="sc">}</span><span class="ss">/pipeline.joblib'</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        final_output_path <span class="op">=</span> <span class="op">\</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f'</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>io_handler<span class="sc">.</span>fpath_dict<span class="sc">.</span>pipeline<span class="sc">}</span><span class="ss">/pipeline.joblib'</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> interim_output_path, final_output_path</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _load_train_data(<span class="va">self</span>):</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        X_train <span class="op">=</span> <span class="va">self</span>.io_handler.load(<span class="st">'X_train'</span>)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        y_train <span class="op">=</span> <span class="va">self</span>.io_handler.load(<span class="st">'y_train'</span>)[<span class="st">'species'</span>]</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X_train, y_train</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _load_transformer(<span class="va">self</span>):</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        normalizer_wrapper <span class="op">=</span> FeatureNormalizer(<span class="va">self</span>.params, load<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.normalizer <span class="op">=</span> normalizer_wrapper.normalizer</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initiate_learner(<span class="va">self</span>):</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learner <span class="op">=</span> LogisticRegression()</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _make_pipeline(<span class="va">self</span>):</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pipeline <span class="op">=</span> make_pipeline(</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.normalizer,</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.learner)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _fit(<span class="va">self</span>, X_train, y_train):</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pipeline.fit(X_train, y_train)</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _persist_pipeline(<span class="va">self</span>):</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Temporarily save model to disk</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>        joblib.dump(<span class="va">self</span>.pipeline, <span class="va">self</span>.interim_output_path)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Copy model to GCS</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.params.env_name <span class="op">!=</span> <span class="st">'local'</span>:</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"Persisting </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>final_output_path<span class="sc">}</span><span class="ss">..."</span>)</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>            subprocess.check_output([</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>                <span class="st">'gsutil'</span>, <span class="st">'-m'</span>, <span class="st">'cp'</span>, <span class="st">'-r'</span>,</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.interim_output_path,</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.final_output_path])</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> run(<span class="va">self</span>):</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>        X_train, y_train <span class="op">=</span> <span class="va">self</span>._load_train_data()</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._load_transformer()</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._initiate_learner()</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._make_pipeline()</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._fit(X_train, y_train)</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._persist_pipeline()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details>
<p>As you can see in the snippet above, the class <code>Trainer</code> expose a function <code>run</code>. Each step in the process corresponds to a private function declared in the same class.</p>
<p><code>shared/</code>: functions and classes to be reused across modules</p>
<p>In <code>io_handler.py</code>, the class IOHandler applies the principle <a href="https://en.wikipedia.org/wiki/Composition_over_inheritance">Composition Over Inheritance</a> to ease the process of loading outputs from the previous step.</p>
</section>
<section id="further-discussion" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="further-discussion">Further discussion</h2>
<p>To completely build and operate a pipeline, there is still more to be considered.</p>
<section id="apache-spark-for-bigger-data" class="level3">
<h3 class="anchored" data-anchor-id="apache-spark-for-bigger-data">Apache Spark for bigger&nbsp;data</h3>
<p>In this tutorial, we rent one small machine from Dataproc and use pandas as our preprocessing engine, which perfectly handles the case of data fit into the memory of that machine. However, often data input in real-world situations will be much bigger, therefore require us to use a distributed computing framework for scalability. In that case, you can just switch to using Apache Spark. From version 1.3, Spark introduces its DataFrame API, which greatly bears resemblance to Pandas counterpart. After porting your code from Pandas to Spark, to be able to run jobs across multiple machines, you just need to create a bigger cluster with a master and multiple workers.</p>
</section>
<section id="apache-airflow-for-orchestration" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="apache-airflow-for-orchestration">Apache Airflow for orchestration</h3>
<p>Most of the batch job is not ad hoc. If it is, we should not even think about putting effort to standardize the process in the first place. <a href="https://airflow.apache.org/">Apache Airflow</a> can play the role of both a scheduler and a monitor. It keeps metadata of each run and can send you alerts when things fail.</p>
<div class="page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="https://cdn-images-1.medium.com/max/800/1*2DPJcNVFajHrm4WjTqI9dA.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-10" title="Example of Airflow DAG: Source"><img src="https://cdn-images-1.medium.com/max/800/1*2DPJcNVFajHrm4WjTqI9dA.png" class="img-fluid figure-img column-page" alt="Example of Airflow DAG: Source"></a></p>
<figcaption>Example of Airflow DAG: <a href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwiHu5jc1dfmAhWULqYKHaQKBBAQjRx6BAgBEAQ&amp;url=https%3A%2F%2Fwww.astronomer.io%2Fguides%2Fsubdags&amp;psig=AOvVaw1KeFNXmbAOrSVsWWG3HOSK&amp;ust=1577599347094494">Source</a></figcaption>
</figure>
</div>
</div>
<p>An alternative is Dataproc Workflows. This is a native solution offered by GCP, but I haven‚Äôt tried it myself so I will just leave the documentation <a href="https://cloud.google.com/dataproc/docs/concepts/workflows/using-workflows">here</a>.</p>
</section>
<section id="local-development" class="level3">
<h3 class="anchored" data-anchor-id="local-development">Local development</h3>
<p>Because rarely our codes work the first time we write them, it‚Äôs very important to be able to quickly test without having to go through all the boilerplate steps from setting up variables to requesting cloud resources. My suggestion is that we should set up our local environment asap. We can install Apache Spark 2.4.3+ to act as our runner engine, and MongoDB to be our alternative for Cloud Firestore. Here in the code repo, you can still refer to some line containing what I call the ‚Äúenvironment branching logic‚Äù, which enables you to switch between running the same code on both local and cloud environments.</p>
</section>
<section id="unit-testing" class="level3">
<h3 class="anchored" data-anchor-id="unit-testing">Unit testing</h3>
<p>Many people have already talked about unit testing, so I won‚Äôt go too detailed here. I also don‚Äôt do unit testing in this tutorial for the sake of simplicity. However, I strongly encourage you to add testing yourself. Whatever it takes, unit testing forces us to modularize our code and add a layer of alerting. This is very important because things in data science often break in silence.</p>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Here is a summary of what you have learned in this tutorial:</p>
<ol type="1">
<li>How to utilize different Google Cloud Platform components to build a batch job pipeline (whether it involves ML or not).</li>
<li>A product named Google Cloud Dataproc, where you can both submit a light-weight job via single-node mode and easily scale to a cluster of computers.</li>
<li>One approach to structurize ML pipeline codebase: <a href="https://github.com/dvquy13/gcp_ml_pipeline">Link to the repo</a>.</li>
<li>Some convenient components in model development, e.g.&nbsp;Makefile, runtime config, parquet persistence. This mostly helps people with little or no software engineering background.</li>
</ol>
<p>Again, one of my main goals in writing this article is to receive feedback from the community, so I can do my job better. Please feel free me leave me comments, and I hope you guys enjoy this tutorial.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ol type="1">
<li><p>Ricky Kim. (Dec 2018). PySpark Sentiment Analysis on Google Dataproc. towardsdatascience.com. <a href="https://towardsdatascience.com/step-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468">https://towardsdatascience.com/step-by-step-tutorial-pyspark-sentiment-analysis-on-google-dataproc-fef9bef46468</a>.</p></li>
<li><p>Evan Kampf. (Jan 2017). Best Practices Writing Production-Grade PySpark Jobs. developerzen.com. <a href="https://developerzen.com/best-practices-writing-production-grade-pyspark-jobs-cb688ac4d20f">https://developerzen.com/best-practices-writing-production-grade-pyspark-jobs-cb688ac4d20f</a>.</p></li>
<li><p>King Chung Huang. (Oct 2017). Don‚Äôt Repeat Yourself with Anchors, Aliases and Extensions in Docker Compose Files. medium.com. <a href="https://medium.com/@kinghuang/docker-compose-anchors-aliases-extensions-a1e4105d70bd">https://medium.com/<span class="citation" data-cites="kinghuang/docker-compose-anchors-aliases-extensions-a1e4105d70bd">@kinghuang/docker-compose-anchors-aliases-extensions-a1e4105d70bd</span></a>.</p></li>
</ol>
<hr>
</section>
<section id="credits" class="level2">
<h2 class="anchored" data-anchor-id="credits">Credits</h2>
<p>Kudos to Bido for reviewing my work; to anh Khanh, anh Linh, anh Tuan for providing me feedback.</p>
<p><br> If you find this article helpful, please cite this writeup as:</p>
<blockquote class="blockquote">
<p>Quy, Dinh. (Feb 2020). From Model to Production: Deploying Your Machine Learning Solution on Google Cloud. dvquys.com. https://dvquys.com/posts/deploy-ml-gcp/.</p>
</blockquote>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/dvquys\.com");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="dvquy13/icy-touch-comments" data-repo-id="R_kgDONEpzPA" data-category="General" data-category-id="DIC_kwDONEpzPM4Cjn8n" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark">
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">

<div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"loop":false,"descPosition":"bottom","closeEffect":"zoom","selector":".lightbox","openEffect":"zoom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>